{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autotrim\n",
    "> Generate suggested trims based on the elimination information extracted from a given video.\n",
    "\n",
    "To achieve this, we'll need to implement some form of provenance tracking functionality to figure out if the last n kills of a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp autotrim\n",
    "#| export\n",
    "import enum\n",
    "import dataclasses\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "from typing import Any, List, Optional, Tuple, TypeAlias\n",
    "\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "from csgo_clips_autotrim.experiment_utils.utils import getLogger\n",
    "from csgo_clips_autotrim.segmentation.elimination import EliminationSegmentationResult, EliminationEvent, FrameInfo\n",
    "\n",
    "\n",
    "logger = getLogger('autotrim')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clutch detection\n",
    "> Classify if the given clip was a clutch or not, and if it is, find the cutpoints to trim the clip to the clutch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class EventType(enum.Enum):\n",
    "    ELIMINATION = 'ELIMINATION',\n",
    "    ROUND_END = 'ROUND_END'\n",
    "\n",
    "def similarity(event1: EliminationEvent, event2: EliminationEvent) -> float:\n",
    "    \"\"\"Find similarity between two elimination event, to find new events in the\n",
    "    timeline.\n",
    "\n",
    "    Args:\n",
    "        event1 (EliminationEvent)\n",
    "        event2 (EliminationEvent)\n",
    "\n",
    "    Returns:\n",
    "        float\n",
    "    \"\"\"\n",
    "    if event1.eliminated.ocr is None or event2.eliminator.ocr is None:\n",
    "        raise ValueError('Need ocr information in given events to find out similarity.')\n",
    "    \n",
    "    ratios = []\n",
    "    ratios.append(fuzz.WRatio(event1.eliminated.ocr.text, event2.eliminated.ocr.text))\n",
    "    ratios.append(fuzz.WRatio(event1.eliminator.ocr.text, event2.eliminator.ocr.text))\n",
    "\n",
    "    return ratios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class TimelineEvent:\n",
    "    frame_info: FrameInfo\n",
    "    event: EliminationEvent\n",
    "\n",
    "Timeline: TypeAlias = List[TimelineEvent]\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class ClutchDetectionResult:\n",
    "    num_kills: int\n",
    "\n",
    "def find_closest_event_from_result(event: EliminationEvent, result: EliminationSegmentationResult, threshold: int = 85) -> Optional[EliminationEvent]:\n",
    "    for e0 in result.elimination_events:\n",
    "        if all(map(lambda x: x > threshold, similarity(event, e0))):\n",
    "            return e0\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_timeline(segmentation_result_path: os.PathLike, threshold: int = 85) -> Timeline:\n",
    "    \"\"\"Get timeline of elimination events from the segmentation results.\n",
    "\n",
    "    Args:\n",
    "        segmentation_result_path (os.PathLike)\n",
    "        threshold (int, optional): Threshold used for similarity scanning. Defaults to 85.\n",
    "\n",
    "    Returns:\n",
    "        Timeline: _description_\n",
    "    \"\"\"\n",
    "    segmentation_result_path = pathlib.Path(segmentation_result_path)\n",
    "    elimination_results_files = list(segmentation_result_path.glob('*.json'))\n",
    "\n",
    "    elimination_results = []\n",
    "    for path in elimination_results_files:\n",
    "        with open(path, 'r') as f:\n",
    "            try:\n",
    "                result = EliminationSegmentationResult.schema().loads(f.read())\n",
    "                elimination_results.append(result)\n",
    "            except:\n",
    "                logger.exception('Failed to load file: %s', path)\n",
    "\n",
    "    elimination_results_by_time: List[EliminationSegmentationResult] = sorted(elimination_results, key=lambda x: x.frame_info.idx)\n",
    "    timeline: Timeline = []\n",
    "    num_frames = len(elimination_results)\n",
    "\n",
    "    for idx, result in enumerate(elimination_results_by_time[1:], start=1):\n",
    "        r0 = elimination_results_by_time[idx - 1]\n",
    "        r1 = result\n",
    "\n",
    "        for e1 in r1.elimination_events:\n",
    "            seen = False\n",
    "\n",
    "            for e0 in r0.elimination_events:\n",
    "                if any(map(lambda x: x > threshold, similarity(e1, e0))):\n",
    "                    seen = True\n",
    "                    break\n",
    "\n",
    "            if not seen:\n",
    "                # Lookahead next few frames to figure out the most confident OCR preds.\n",
    "                lookahead_frames = min(5, num_frames - idx - 1)\n",
    "\n",
    "                best_eliminator = e1.eliminator\n",
    "                best_eliminated = e1.eliminated\n",
    "\n",
    "                for lidx in range(lookahead_frames):\n",
    "                    lookahead_result = elimination_results_by_time[idx + lidx]\n",
    "                    closest_event = find_closest_event_from_result(e1, lookahead_result)\n",
    "\n",
    "                    if not closest_event:\n",
    "                        logger.warning('Lookahead did not find any matching event in next frames.')\n",
    "                        continue\n",
    "\n",
    "                    if closest_event.eliminator.ocr.confidence > best_eliminator.ocr.confidence:\n",
    "                        best_eliminator = closest_event.eliminator\n",
    "\n",
    "                    if closest_event.eliminated.ocr.confidence > best_eliminated.ocr.confidence:\n",
    "                        best_eliminated = closest_event.eliminated\n",
    "                \n",
    "                best_event = dataclasses.replace(e1, eliminator=best_eliminator, eliminated=best_eliminated)\n",
    "                timeline.append(TimelineEvent(r1.frame_info, best_event))\n",
    "\n",
    "    return timeline\n",
    "\n",
    "\n",
    "def detect_clutch(timeline: Timeline) -> ClutchDetectionResult:\n",
    "    \"\"\"Detect if the given timeline is a clutch.\n",
    "\n",
    "    Args:\n",
    "        timeline (Timeline)\n",
    "\n",
    "    Returns:\n",
    "        ClutchDetectionResult\n",
    "    \"\"\"\n",
    "    # Approach: check if the last n kills have the same eliminator.\n",
    "    # This will miss cases when the eliminator dies last but still the round is won (b)\n",
    "\n",
    "    # TODO: Need to find the following things to improve accuracy.\n",
    "    # 1. Which team won\n",
    "    # 2. Round end\n",
    "    # 3. Number of enemies remaining.\n",
    "    last_eliminator = timeline[-1].event.eliminator\n",
    "    threshold: int = 60\n",
    "\n",
    "    num_events = min(5, len(timeline))\n",
    "    potential_clutch_events = timeline[-num_events:-1]\n",
    "    num_kills = 1\n",
    "\n",
    "    for timeline_event in reversed(potential_clutch_events):\n",
    "        if fuzz.WRatio(timeline_event.event.eliminator.ocr.text, last_eliminator.ocr.text) < threshold:\n",
    "            break\n",
    "        num_kills += 1\n",
    "\n",
    "    return ClutchDetectionResult(num_kills=num_kills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClutchDetectionResult(num_kills=4)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from csgo_clips_autotrim.experiment_utils.constants import BASE_DIR\n",
    "\n",
    "TEST_DIR = BASE_DIR / 'nbs' / 'out' / 'work-dir' / 'provenance'\n",
    "timeline = get_timeline(TEST_DIR)\n",
    "detect_clutch(timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csgo-clips-autotrim-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
