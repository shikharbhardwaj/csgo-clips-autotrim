{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autotrim\n",
    "> Generate suggested trims based on the elimination information extracted from a given video.\n",
    "\n",
    "To achieve this, we'll need to implement some form of provenance tracking functionality to figure out if the last n kills of a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2023-08-20 16:52:16,365 torch.distributed.nn.jit.instantiator: Created a temporary directory at /tmp/tmp7lfidso8\n",
      "[INFO] 2023-08-20 16:52:16,366 torch.distributed.nn.jit.instantiator: Writing /tmp/tmp7lfidso8/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "#| default_exp autotrim\n",
    "#| export\n",
    "import enum\n",
    "import dataclasses\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "from typing import List, Optional, TypeAlias\n",
    "\n",
    "import dataclasses_json\n",
    "import numpy as np\n",
    "import numpy.typing as nptypes\n",
    "from PIL import Image\n",
    "from rapidfuzz import fuzz\n",
    "import scipy.cluster\n",
    "import scipy.spatial\n",
    "import scipy.misc\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from csgo_clips_autotrim.experiment_utils.utils import getLogger\n",
    "from csgo_clips_autotrim.experiment_utils.config import InferenceConfig\n",
    "from csgo_clips_autotrim.segmentation.elimination import EliminationSegmentationResult, EliminationEvent, FrameInfo, get_inference_result, preprocess_image, crop_img_to_bbox, XYXYBBox\n",
    "\n",
    "\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clutch detection\n",
    "> Classify if the given clip was a clutch or not, and if it is, find the cutpoints to trim the clip to the clutch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class EventType(enum.Enum):\n",
    "    ELIMINATION = 'ELIMINATION',\n",
    "    ROUND_END = 'ROUND_END'\n",
    "\n",
    "def similarity(event1: EliminationEvent, event2: EliminationEvent) -> float:\n",
    "    \"\"\"Find similarity between two elimination event, to find new events in the\n",
    "    timeline.\n",
    "\n",
    "    Args:\n",
    "        event1 (EliminationEvent)\n",
    "        event2 (EliminationEvent)\n",
    "\n",
    "    Returns:\n",
    "        float\n",
    "    \"\"\"\n",
    "    if event1.eliminated.ocr is None or event2.eliminator.ocr is None:\n",
    "        raise ValueError('Need ocr information in given events to find out similarity.')\n",
    "    \n",
    "    ratios = []\n",
    "    ratios.append(fuzz.WRatio(event1.eliminator.ocr.text, event2.eliminator.ocr.text))\n",
    "    ratios.append(fuzz.WRatio(event1.eliminated.ocr.text, event2.eliminated.ocr.text))\n",
    "\n",
    "    return ratios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@dataclasses_json.dataclass_json\n",
    "@dataclasses.dataclass\n",
    "class TimelineEvent:\n",
    "    frame_info: FrameInfo\n",
    "    event: EliminationEvent\n",
    "\n",
    "class GameStateLabel(enum.Enum):\n",
    "    CT_WIN = 0\n",
    "    ELIMINATOR_MARK = 1\n",
    "    T_WIN = 2\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class GameStateElement:\n",
    "    label: GameStateLabel\n",
    "    bbox: XYXYBBox\n",
    "\n",
    "Timeline: TypeAlias = List[TimelineEvent]\n",
    "\n",
    "@dataclasses_json.dataclass_json\n",
    "@dataclasses.dataclass\n",
    "class ClutchDetectionResult:\n",
    "    num_eliminations: int\n",
    "    player: str\n",
    "    start_frame_idx: int\n",
    "    end_frame_idx: int\n",
    "\n",
    "\n",
    "def get_dominant_color(img_ar: nptypes.ArrayLike) -> nptypes.ArrayLike:\n",
    "    NUM_CLUSTERS = 5\n",
    "\n",
    "    shape = img_ar.shape\n",
    "    frame_ar = img_ar.reshape(np.product(shape[:2]), shape[2]).astype(float)\n",
    "    codes, dist = scipy.cluster.vq.kmeans(frame_ar, NUM_CLUSTERS)\n",
    "    vecs, dist = scipy.cluster.vq.vq(frame_ar, codes)\n",
    "    counts, bins = np.histogram(vecs, len(codes))\n",
    "    index_max = np.argmax(counts)\n",
    "    peak = codes[index_max]\n",
    "\n",
    "    return peak\n",
    "\n",
    "def is_eliminator_win(last_frame_img_np: nptypes.ArrayLike, last_event: TimelineEvent, win_element_bbox: XYXYBBox) -> bool:\n",
    "    \"\"\"Find if the eliminator won the round.\n",
    "\n",
    "    Args:\n",
    "        last_frame_img_np (nptypes.ArrayLike)\n",
    "        last_event (TimelineEvent)\n",
    "        win_element_bbox (XYXYBBox)\n",
    "\n",
    "    Returns:\n",
    "        bool\n",
    "    \"\"\"\n",
    "    h, w, _ = last_frame_img_np.shape\n",
    "    top_right_quad = last_frame_img_np[0:h // 2, w // 2:w]\n",
    "\n",
    "    eliminator_img_np = crop_img_to_bbox(top_right_quad, last_event.event.eliminator.bbox)\n",
    "    eliminator_dominant_color = get_dominant_color(eliminator_img_np)\n",
    "\n",
    "    win_img_np = crop_img_to_bbox(last_frame_img_np, win_element_bbox)\n",
    "    win_dominant_color = get_dominant_color(win_img_np)\n",
    "\n",
    "    eliminated_img_np = crop_img_to_bbox(top_right_quad, last_event.event.eliminated.bbox)\n",
    "    eliminated_dominant_color = get_dominant_color(eliminated_img_np)\n",
    "\n",
    "    return scipy.spatial.distance.euclidean(eliminator_dominant_color, win_dominant_color) < scipy.spatial.distance.euclidean(eliminated_dominant_color, win_dominant_color) \n",
    "\n",
    "def diff_events(events_0: List[EliminationEvent], events_1: List[EliminationEvent], threshold: int = 40) -> List[EliminationEvent]:\n",
    "    \"\"\"Given a pair of events, find out which events do not exist in the 2nd list.\n",
    "\n",
    "    Args:\n",
    "        events_0 (List[EliminationEvent])\n",
    "        events_1 (List[EliminationEvent])\n",
    "\n",
    "    Returns:\n",
    "        List[EliminationEvent]\n",
    "    \"\"\"\n",
    "    if not events_0 or not events_1:\n",
    "        return events_1\n",
    "\n",
    "    cost_matrix = -1 * np.asarray(\n",
    "        [[min(similarity(e0, e1)) for e1 in events_1] for e0 in events_0]\n",
    "    )\n",
    "\n",
    "    row_idx, col_idx = linear_sum_assignment(cost_matrix)\n",
    "\n",
    "    matched_events = set()\n",
    "\n",
    "    for ridx, cidx in zip(row_idx, col_idx):\n",
    "        if abs(cost_matrix[ridx][cidx]) > threshold:\n",
    "            logger.debug('Found match in previous frame for event: (%d, %d)', ridx, cidx)\n",
    "            matched_events.add(cidx)\n",
    "    \n",
    "    return [x for idx, x in enumerate(events_1) if idx not in matched_events]\n",
    "\n",
    "def get_elimination_segmentation_results(segmentation_result_path: os.PathLike) -> List[EliminationSegmentationResult]:\n",
    "    elimination_results_files = list(segmentation_result_path.glob('*.json'))\n",
    "\n",
    "    elimination_results = []\n",
    "    for path in elimination_results_files:\n",
    "        with open(path, 'r') as f:\n",
    "            try:\n",
    "                result = EliminationSegmentationResult.schema().loads(f.read())\n",
    "                elimination_results.append(result)\n",
    "            except:\n",
    "                logger.exception('Failed to load file: %s', path)\n",
    "    \n",
    "    return elimination_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_timeline(segmentation_result_path: os.PathLike, threshold: int = 50) -> Timeline:\n",
    "    \"\"\"Get timeline of elimination events from the segmentation results.\n",
    "\n",
    "    Args:\n",
    "        segmentation_result_path (os.PathLike)\n",
    "        threshold (int, optional): Threshold used for similarity scanning. Defaults to 65.\n",
    "\n",
    "    Returns:\n",
    "        Timeline: _description_\n",
    "    \"\"\"\n",
    "    segmentation_result_path = pathlib.Path(segmentation_result_path)\n",
    "\n",
    "    elimination_results = get_elimination_segmentation_results(segmentation_result_path)\n",
    "\n",
    "    elimination_results_by_time: List[EliminationSegmentationResult] = sorted(elimination_results, key=lambda x: x.frame_info.idx)\n",
    "    timeline: Timeline = []\n",
    "    num_frames = len(elimination_results)\n",
    "\n",
    "    for idx, result in enumerate(elimination_results_by_time):\n",
    "        events = result.elimination_events\n",
    "        num_events = len(events)\n",
    "        \n",
    "        # Get the last n events for matching.\n",
    "        past_events_to_lookup = max(5, num_events)\n",
    "        past_events = [e.event for e in timeline[-past_events_to_lookup:] if e.frame_info.idx > result.frame_info.idx - 10]\n",
    "        new_events = diff_events(past_events, events, 50)\n",
    "\n",
    "        if new_events:\n",
    "            logger.info('Found %d new events in frame %d', len(new_events), idx)\n",
    "            logger.debug('Past events: [%s]', \", \".join(map(str, past_events)))\n",
    "            logger.debug('New events: [%s]', \", \".join(map(str, new_events)))\n",
    "\n",
    "        lookahead_frames = min(10, num_frames - idx - 1)\n",
    "\n",
    "        for event in new_events:\n",
    "            best_eliminator = event.eliminator\n",
    "            best_eliminated = event.eliminated\n",
    "\n",
    "            for lidx in range(lookahead_frames):\n",
    "                lookahead_events = elimination_results_by_time[idx + lidx].elimination_events\n",
    "\n",
    "                # Find closest matching.\n",
    "                cost_matrix = -1 * np.asarray(\n",
    "                    [[min(similarity(e0, e1)) for e1 in lookahead_events] for e0 in result.elimination_events]\n",
    "                )\n",
    "\n",
    "                row_idx, col_idx = linear_sum_assignment(cost_matrix)\n",
    "\n",
    "                eidx = events.index(event)\n",
    "                if eidx not in row_idx:\n",
    "                    logger.warning('Lookahead did not find any matching event in next frame: %d.', lidx)\n",
    "                    continue\n",
    "\n",
    "                i = row_idx.tolist().index(eidx)\n",
    "                ridx = row_idx[i]\n",
    "                cidx = col_idx[i]\n",
    "\n",
    "                if abs(cost_matrix[ridx][cidx]) < threshold:\n",
    "                    logger.warning('Lookahead found event lower than threshold for frame: %d.', lidx)\n",
    "                    continue\n",
    "\n",
    "                closest_event = lookahead_events[cidx]\n",
    "\n",
    "                if closest_event.eliminator.ocr.confidence > best_eliminator.ocr.confidence + 0.1:\n",
    "                    best_eliminator = closest_event.eliminator\n",
    "\n",
    "                if closest_event.eliminated.ocr.confidence > best_eliminated.ocr.confidence + 0.1:\n",
    "                    best_eliminated = closest_event.eliminated\n",
    "\n",
    "            best_event = dataclasses.replace(event, eliminator=best_eliminator, eliminated=best_eliminated)\n",
    "\n",
    "            min_ocr_confidence = min(best_event.eliminated.ocr.confidence,\n",
    "                                     best_event.eliminator.ocr.confidence)\n",
    "            \n",
    "            if min_ocr_confidence > 0.4:\n",
    "                timeline.append(TimelineEvent(frame_info=result.frame_info, event=best_event))\n",
    "\n",
    "    return timeline\n",
    "\n",
    "\n",
    "def get_frame(frame_info: FrameInfo, image_dir: os.PathLike) -> nptypes.ArrayLike:\n",
    "    \"\"\"Get the frame as a numpy array for given frame info.\n",
    "\n",
    "    Args:\n",
    "        frame_info (FrameInfo)\n",
    "        image_dir (os.PathLike)\n",
    "\n",
    "    Returns:\n",
    "        nptypes.ArrayLike\n",
    "    \"\"\"\n",
    "    frame_path = pathlib.Path(image_dir) / f'{frame_info.name}.png'\n",
    "    with Image.open(frame_path, 'r') as f:\n",
    "        return np.asarray(f)\n",
    "\n",
    "def detect_game_state_elements(frame_info: FrameInfo, image_dir: os.PathLike, inference_config: InferenceConfig) -> List[GameStateElement]:\n",
    "    \"\"\"Detect game state elements from the given frame.\n",
    "\n",
    "    Args:\n",
    "        frame_info (FrameInfo)\n",
    "        image_dir (os.PathLike)\n",
    "\n",
    "    Returns:\n",
    "        List[GameStateLabel]\n",
    "    \"\"\"\n",
    "    frame_img = get_frame(frame_info, image_dir)\n",
    "    preprocess_result = preprocess_image(frame_img, inference_config.mlflow_artifact_run_id)\n",
    "    results = get_inference_result(preprocess_result, inference_config)\n",
    "\n",
    "    return [GameStateElement(bbox=result.bbox, label=GameStateLabel(result.label)) for result in results]\n",
    "\n",
    "def detect_clutch(timeline: Timeline, image_dir: os.PathLike, game_state_inference_config: InferenceConfig) -> Optional[ClutchDetectionResult]:\n",
    "    \"\"\"Detect if the given timeline is a clutch.\n",
    "\n",
    "    Args:\n",
    "        timeline (Timeline)\n",
    "\n",
    "    Returns:\n",
    "        ClutchDetectionResult\n",
    "    \"\"\"\n",
    "    # Check if the last event in the timeline has game state elements that make this a clutch.\n",
    "    last_event = timeline[-1]\n",
    "\n",
    "    last_event_game_state_elements = detect_game_state_elements(last_event.frame_info, image_dir, game_state_inference_config)\n",
    "\n",
    "    if not last_event_game_state_elements:\n",
    "        logger.info('Did not find any game state elements in the last timeline event, no clutch detected.')\n",
    "        return None\n",
    "    \n",
    "    win_element = list(filter(lambda x: x.label in (GameStateLabel.CT_WIN, GameStateLabel.T_WIN), last_event_game_state_elements))\n",
    "\n",
    "    if not win_element:\n",
    "        logger.info('Did not find any win elements in the last timline event, no clutch detected.')\n",
    "        return None\n",
    "\n",
    "    if len(win_element) > 1:\n",
    "        logger.warning('Found multiple win elements in the last timeline event. Using first for further inference.')\n",
    "\n",
    "    win_element = win_element[0]\n",
    "\n",
    "    # Check if the team of the last eliminator won.\n",
    "    last_frame_img_np = get_frame(last_event.frame_info, image_dir)\n",
    "\n",
    "    if not is_eliminator_win(last_frame_img_np, last_event, win_element.bbox):\n",
    "        logger.info('Eliminator did not win the last engagement.')\n",
    "        return None\n",
    "    \n",
    "    # Check if the eliminator was the last alive.\n",
    "    teammates_eliminated_marks = list(filter(lambda x: x.label == GameStateLabel.ELIMINATOR_MARK, last_event_game_state_elements))\n",
    "\n",
    "    if len(teammates_eliminated_marks) != 4:\n",
    "        logger.info('The last eliminator had %d teammates eliminated, no clutch detected.', len(teammates_eliminated_marks))\n",
    "        return ClutchDetectionResult()\n",
    "\n",
    "    # Count the number of teammates alive at the win condition.\n",
    "    last_eliminator = timeline[-1].event.eliminator\n",
    "    threshold: int = 75\n",
    "\n",
    "    num_events = min(5, len(timeline))\n",
    "    potential_clutch_events = timeline[-num_events:-1]\n",
    "    num_eliminations = 1\n",
    "\n",
    "    for timeline_event in reversed(potential_clutch_events):\n",
    "        if fuzz.WRatio(timeline_event.event.eliminator.ocr.text, last_eliminator.ocr.text) < threshold:\n",
    "            break\n",
    "        num_eliminations += 1\n",
    "    \n",
    "    first_clutch_elimination = timeline[-num_eliminations]\n",
    "    last_clutch_elimination = timeline[-1]\n",
    "\n",
    "    return ClutchDetectionResult(num_eliminations=num_eliminations,\n",
    "                                 player=last_eliminator.ocr.text,\n",
    "                                 start_frame_idx=first_clutch_elimination.frame_info.idx,\n",
    "                                 end_frame_idx=last_clutch_elimination.frame_info.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2023-08-20 17:02:09,850 root        : Found 1 new events in frame 1\n",
      "[INFO] 2023-08-20 17:02:09,851 root        : Found 1 new events in frame 21\n",
      "[INFO] 2023-08-20 17:02:09,852 root        : Found 2 new events in frame 28\n",
      "[INFO] 2023-08-20 17:02:09,853 root        : Found 2 new events in frame 37\n",
      "[INFO] 2023-08-20 17:02:09,855 root        : Found 1 new events in frame 39\n",
      "[INFO] 2023-08-20 17:02:09,857 root        : Found 1 new events in frame 49\n",
      "[INFO] 2023-08-20 17:02:09,858 root        : Found 1 new events in frame 82\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClutchDetectionResult(num_eliminations=4, player='Oblue', start_frame_idx=37, end_frame_idx=82)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from csgo_clips_autotrim.experiment_utils.constants import BASE_DIR\n",
    "\n",
    "TEST_DIR = BASE_DIR / 'nbs' / 'out' / 'work-dir' / 'autotrim'\n",
    "SEGMENTATION_RESULT = TEST_DIR / 'segmentation-results'\n",
    "IMAGE_DIR = TEST_DIR / 'frames'\n",
    "game_state_inference_config = InferenceConfig(mlflow_artifact_run_id='2fe893e46e554b1e8b1ae44176677fb3', triton_model_name='csgo-game-state-segmentation-yolov8', triton_url='localhost:8000', score_threshold=0.5)\n",
    "timeline = get_timeline(SEGMENTATION_RESULT)\n",
    "detect_clutch(timeline, IMAGE_DIR, game_state_inference_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2023-08-20 17:02:24,152 root        : Found 1 new events in frame 1\n",
      "[INFO] 2023-08-20 17:02:24,153 root        : Found 1 new events in frame 21\n",
      "[INFO] 2023-08-20 17:02:24,154 root        : Found 2 new events in frame 28\n",
      "[INFO] 2023-08-20 17:02:24,155 root        : Found 2 new events in frame 37\n",
      "[INFO] 2023-08-20 17:02:24,156 root        : Found 1 new events in frame 39\n",
      "[INFO] 2023-08-20 17:02:24,157 root        : Found 1 new events in frame 49\n",
      "[INFO] 2023-08-20 17:02:24,158 root        : Found 1 new events in frame 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "timeline = get_timeline(SEGMENTATION_RESULT)\n",
    "print(len(timeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csgo-clips-autotrim-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
